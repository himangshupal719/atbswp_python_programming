Hypertext Markup Language (HTML) is the format that web pages are written in.

An HTML file is a plaintext file with the .html file extension. The text in these files is surrounded by tags, which are words enclosed in angle brackets. The tags tell the browser how to format the web page. A starting tag and closing tag can enclose some text to form an element. The text (or inner HTML) is the content between the starting and closing tags.

<strong>Hello</strong>,world!

The opening <strong> tag says that the enclosed text will appear in bold. The closing </strong> tags tells the browser where the end of the bold text is.

There are many different tags in HTML. Some of these tags have extra properties in the form of attributes within the angle brackets.
For example, the <a> tag encloses text that should be a link. The URL that the text links to is determined by the href attribute. Here’s an example:

Al's free <a href="https://inventwithpython.com">Python books</a>.

Some elements have an id attribute that is used to uniquely identify the element in the page. You will often instruct your programs to seek out an element by its id attribute, so figuring out an element’s id attribute using the browser’s developer tools is a common task in writing web scraping programs.



Viewing the Source HTML of a Web Page
--------------------------------------

right-click (or CTRL-click on macOS) any web page in your web browser, and select View Source or View page source to see the HTML text of the page.

Opening Browser's Developer Tools
----------------------------------
In Chrome and Internet Explorer for Windows, the developer tools are already installed, and you can press F12 to make them appear.

In Chrome, you can also bring up the developer tools by selecting View ▸ Developer ▸ Developer Tools.

After enabling or installing the developer tools in your browser, you can right-click any part of the web page and select Inspect Element from the context menu to bring up the HTML responsible for that part of the page. 

Don't Use Regular Expression to Parse HTML:
----------------------------------------------
Locating a specific piece of HTML in a string seems like a perfect case for regular expressions. However, I advise you against it. There are many different ways that HTML can be formatted and still be considered valid HTML, but trying to capture all these possible variations in a regular expression can be tedious and error prone. A module developed specifically for parsing HTML, such as bs4, will be less likely to result in bugs.



Using the Developer Tools to find the HTML Elements:
-----------------------------------------------------

Once your program has downloaded a web page using the requests module, you will have the page’s HTML content as a single string value. Now you need to figure out which part of the HTML corresponds to the information on the web page you’re interested in. This is where the browser’s developer tools can help. 

 Right-click where it is on the page (or CONTROL-click on macOS) and select Inspect Element from the context menu that appears. 


Parsing HTML with the BS4 Module
----------------------------------
Beautiful Soup is a module for extracting information from an HTML page (and is much better for this purpose than regular expressions). 
The Beautiful Soup module’s name is bs4 (for Beautiful Soup, version 4).
While beautifulsoup4 is the name used for installation, to import Beautiful Soup you run import bs4.

the Beautiful Soup examples will parse (that is, analyze and identify the parts of) an HTML file on the hard drive.

Creating Beautiful Object From HTML
-----------------------------------
The bs4.BeautifulSoup() function needs to be called with a string containing the HTML it will parse. The bs4.BeautifulSoup() function returns a BeautifulSoup object.

>>> import bs4, requests
>>> res = requests.get('https://nostarch.com')
>>> res
<Response [200]>
>>> res.raise_for_status()
>>> res.status_code
200
>>> res.status_code == requests.codes.ok
True
>>> noStarchSoup=bs4.BeautifulSoup(res.text, 'html.parser')
>>> type(noStarchSoup)
<class 'bs4.BeautifulSoup'>


>>> os.getcwd()
'C:\\Users\\himan\\OneDrive\\Documents\\Interview_Prep\\My_Learning_Cognizant\\atbswpython\\atbswp_python_programming\\40_parsing_html'
>>> exampleFile = open('example.html')
>>> exampleSoup = bs4.BeautifulSoup('exampleFile','html.parser')
>>> type(exampleSoup)
<class 'bs4.BeautifulSoup'>

The 'html.parser' parser used here comes with Python. However, you can use the faster 'lxml' parser if you install the third-party lxml module. Use - pip install --user lxml

Forgetting to include this second argument will result in a UserWarning: No parser was explicitly specified warning.

Once you have a BeautifulSoup object, you can use its methods to locate specific parts of an HTML document.

Finding an Element with select() Method
----------------------------------------
You can retrieve a web page element from a BeautifulSoup object by calling the select()method and passing a string of a CSS selector for the element you are looking for. Selectors are like regular expressions: they specify a pattern to look for—in this case, in HTML pages instead of general text strings.



Selector passed to the select() method	- Will match . . .

soup.select('div') - All elements named <div>

soup.select('#author') - The element with an id attribute of author

soup.select('.notice') - All elements that use a CSS class attribute named notice

soup.select('div span') - All elements named <span> that are within an element named <div>

soup.select('div > span') - All elements named <span> that are directly within an element named <div>, with no other element in between

soup.select('input[name]') - All elements named <input> that have a name attribute with any value

soup.select('input[type="button"]') - All elements named <input> that have an attribute named type with value button

Instead of writing the selector yourself, you can also right-click on the element in your browser and select Inspect Element. When the browser’s developer console opens, right-click on the element’s HTML and select Copy ▸ CSS Selector to copy the selector string to the clipboard and paste it into your source code.

The select() method will return a list of Tag objects, which is how Beautiful Soup represents an HTML element. The list will contain one Tag object for every match in the BeautifulSoup object’s HTML. Tag values can be passed to the str() function to show the HTML tags they represent. Tag values also have an attrs attribute that shows all the HTML attributes of the tag as a dictionary. 



>> myFile = open('example.html')
>>> myFile
<_io.TextIOWrapper name='example.html' mode='r' encoding='cp1252'>
>>> Soup = bs4.BeautifulSoup(myFile.read(), 'html.parser')
>>> Soup
<!-- This is the example.html example file. -->
<html><head><title>The Website Title</title></head>
<body>
<p>Download my <strong>Python</strong> book from <a href="https://
inventwithpython.com">my website</a>.</p>
<p class="slogan">Learn Python the easy way!</p>
<p>By <span id="author">Al Sweigart</span></p>
</body></html>
>>> elems = Soup.select('#author')
>>> type(elems)
<class 'bs4.element.ResultSet'>
>>> len(elems)
1
>>> type(elems[0])
<class 'bs4.element.Tag'>
>>> str(elems[0])
'<span id="author">Al Sweigart</span>'
>>> elems[0].getText()
'Al Sweigart'
>>> elems[0].attrs
{'id': 'author'}


This code will pull the element with id="author" out of our example HTML. We use select('#author') to return a list of all the elements with id="author". We store this list of Tag objects in the variable elems, and len(elems) tells us there is one Tag object in the list; there was one match. Calling getText() on the element returns the element’s text, or inner HTML. The text of an element is the content between the opening and closing tags: in this case, 'Al Sweigart'.

Passing the element to str() returns a string with the starting and closing tags and the element’s text. Finally, attrs gives us a dictionary with the element’s attribute, 'id', and the value of the id attribute, 'author'.


>>> pElems = Soup.select('p')
>>> pElems
[<p>Download my <strong>Python</strong> book from <a href="https://
inventwithpython.com">my website</a>.</p>, <p class="slogan">Learn Python the easy way!</p>, <p>By <span id="author">Al Sweigart</span></p>]
>>> pElems[0].getText()
'Download my Python book from my website.'
>>> str(pElems[1])
'<p class="slogan">Learn Python the easy way!</p>'
>>> pElems[1].getText()
'Learn Python the easy way!'
>>> len(pElems)
3
>>> str(pElems[1])
'<p class="slogan">Learn Python the easy way!</p>'
>>> str(pElems[2])
'<p>By <span id="author">Al Sweigart</span></p>'
>>> pElems[2].getText()
'By Al Sweigart'

select() gives us a list of three matches, which we store in pElems.

Using str() on pElems[0], pElems[1], and pElems[2] shows you each element as a string, and using getText() on each element shows you its text.

Getting Data from an Element's Attributes:
---------------------------------------------

The get() method for Tag objects makes it simple to access attribute values from an element. The method is passed a string of an attribute name and returns that attribute’s value. 	

>>> import bs4
>>> soup = bs4.BeautifulSoup(open('example.html'), 'html.parser')
>>> soup
<!-- This is the example.html example file. -->
<html><head><title>The Website Title</title></head>
<body>
<p>Download my <strong>Python</strong> book from <a href="https://
inventwithpython.com">my website</a>.</p>
<p class="slogan">Learn Python the easy way!</p>
<p>By <span id="author">Al Sweigart</span></p>
</body></html>
>>> spanElem = soup.select('span')[0]
>>> spanElem
<span id="author">Al Sweigart</span>
>>> str(spanElem)
'<span id="author">Al Sweigart</span>'
>>> spanElem.get('id')
'author'
>>> spanElem.get('some_nonexistant_Addr') == None
True
>>> spanElem.attrs
{'id': 'author'}